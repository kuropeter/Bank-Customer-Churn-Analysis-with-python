{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building for Bank Churn Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling\n",
    "import pandas as pd\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Machine Learning Classes\n",
    "from sklearn.preprocessing import LabelEncoder # To convert categorical variables to numerical ones \n",
    "from sklearn.model_selection import train_test_split # To split into train and test datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "# Import Evaluation Modules\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix, roc_auc_score, roc_curve, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and Read Data\n",
    "path = 'Churn_Modelling.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography            int64\n",
       "Gender               int64\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Categorical Variables to numerical variables\n",
    "le = LabelEncoder()\n",
    "cat_var = df[['Geography','Gender']]\n",
    "for x in cat_var:\n",
    "    df[x] = le.fit_transform(df[x])\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are the features we would use to predict churn**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Dependent and Independend Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spliting data to independent and target variables\n",
    "X = df.drop('Exited', axis=1) # Independent Variable\n",
    "y = df['Exited'] # Target Variable\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting Data into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data to Training and testing splits\n",
    "X_train , X_test, y_train, y_test =  train_test_split(X,y, test_size=0.2, random_state=40) \n",
    "# 80% for train, 20% for test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train:  0.788\n",
      "Accuracy Score on Test: 0.8\n",
      "----------------------------------------\n",
      "Precision Score on Train:  0.41365461847389556\n",
      "Precision Score on Test: 0.38\n",
      "----------------------------------------\n",
      "Recall Score on Train:  0.062310949788263764\n",
      "Recall Score on Test: 0.07\n",
      "----------------------------------------\n",
      "AUC-ROC Score on Train:  0.5196539781240042\n",
      "ROC_AUC Score on Test: 0.52\n",
      "----------------------------------------\n",
      "Kappa Score on Test: 0.06\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Prediction for training set\n",
    "log_reg_train = log_reg.predict(X_train) # Baseline Model\n",
    "# Prediction for testing set\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluating Model Results\n",
    "# Accuracy Scores\n",
    "print('Accuracy Score on Train: ', accuracy_score(y_train, log_reg_train))\n",
    "accuracy_lr = accuracy_score(y_test, log_reg_pred).round(2) # Storing score in variable for display \n",
    "print(f'Accuracy Score on Test: {accuracy_lr}')\n",
    "print('--'*20)\n",
    "\n",
    "#Precision Scores \n",
    "print('Precision Score on Train: ', precision_score(y_train, log_reg_train))\n",
    "precision_lr = precision_score(y_test, log_reg_pred).round(2) # Storing score in variable for display \n",
    "print(f'Precision Score on Test: {precision_lr}')\n",
    "print('--'*20)\n",
    "\n",
    "#Recall Scores\n",
    "print('Recall Score on Train: ', recall_score(y_train, log_reg_train))\n",
    "recall_lr = recall_score(y_test, log_reg_pred).round(2) # Storing score in variable for display \n",
    "print(f'Recall Score on Test: {recall_lr}')\n",
    "print('--'*20)\n",
    "\n",
    "# roc_auc_score\n",
    "print('AUC-ROC Score on Train: ', roc_auc_score(y_train, log_reg_train))\n",
    "roc_auc_lr = roc_auc_score(y_test, log_reg_pred).round(2) # Storing score in variable for display \n",
    "print(f'ROC_AUC Score on Test: {roc_auc_lr}')\n",
    "print('--'*20)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_lr = metrics.cohen_kappa_score(y_test, log_reg_pred).round(2) # Storing score in variable for display \n",
    "print(f'Kappa Score on Test: {kappa_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train:  1.0\n",
      "Accuracy Score on Test: 0.79\n",
      "----------------------------------------\n",
      "Precision Score on Train:  1.0\n",
      "Precision Score on Test: 0.46\n",
      "----------------------------------------\n",
      "Recall Score on Train:  1.0\n",
      "Recall Score on Test: 0.51\n",
      "----------------------------------------\n",
      "AUC-ROC Score on Train:  1.0\n",
      "AUC_ROC Score on Test: 0.68\n",
      "----------------------------------------\n",
      "Kappa Score on Test: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Fit Model \n",
    "deci_tree = DecisionTreeClassifier()\n",
    "deci_tree.fit(X_train, y_train)\n",
    "\n",
    "# Prediction for train\n",
    "deci_tree_train = deci_tree.predict(X_train) # Overfitting\n",
    "# Prediction for test\n",
    "deci_tree_pred = deci_tree.predict(X_test)\n",
    "\n",
    "# Evaluating Model Results\n",
    "# Acuracy Score\n",
    "print('Accuracy Score on Train: ', accuracy_score(y_train, deci_tree_train)) \n",
    "accuracy_DT = accuracy_score(y_test, deci_tree_pred).round(2) # Storing score in variable for display \n",
    "print(f'Accuracy Score on Test: {accuracy_DT}')\n",
    "print('--'*20)\n",
    "\n",
    "# Precision Score\n",
    "print('Precision Score on Train: ', precision_score(y_train, deci_tree_train)) \n",
    "precision_DT = precision_score(y_test, deci_tree_pred).round(2) # Storing score in variable for display \n",
    "print(f'Precision Score on Test: {precision_DT}') \n",
    "print('--'*20)\n",
    "\n",
    "# Recall Score\n",
    "print('Recall Score on Train: ', recall_score(y_train, deci_tree_train)) \n",
    "recall_DT = recall_score(y_test, deci_tree_pred).round(2) # Storing score in variable for display \n",
    "print(f'Recall Score on Test: {recall_DT}')\n",
    "print('--'*20)\n",
    "\n",
    "# roc_auc_score\n",
    "print('AUC-ROC Score on Train: ', roc_auc_score(y_train, deci_tree_train))\n",
    "roc_auc_DT = roc_auc_score(y_test, deci_tree_pred).round(2) # Storing score in variable for display \n",
    "print(f'AUC_ROC Score on Test: {roc_auc_DT}')\n",
    "print('--'*20)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_DT = metrics.cohen_kappa_score(y_test, deci_tree_pred).round(2) # Storing score in variable for display \n",
    "print(f'Kappa Score on Test: {kappa_DT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train:  1.0\n",
      "Accuracy Score on Test: 0.87\n",
      "----------------------------------------\n",
      "Precision Score on train:  1.0\n",
      "Precision Score on Test: 0.75\n",
      "----------------------------------------\n",
      "Recall Score on train:  1.0\n",
      "Recall Score on Test: 0.51\n",
      "----------------------------------------\n",
      "AUC-ROC Score on Train:  1.0\n",
      "Recall Score on Test: 0.74\n",
      "----------------------------------------\n",
      "Kappa Score on Test: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "RF = RandomForestClassifier()\n",
    "# Fitting Model\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "# Model Prediction for train\n",
    "RF_train = RF.predict(X_train) #Overfitting\n",
    "# Prediction for test\n",
    "RF_pred = RF.predict(X_test)\n",
    "\n",
    "# Evaluation of Results\n",
    "print('Accuracy Score on Train: ', accuracy_score(y_train, RF_train))\n",
    "accuracy_RF = accuracy_score(y_test, RF_pred).round(2) # Storing score in variable for display \n",
    "print(f'Accuracy Score on Test: {accuracy_RF}')\n",
    "print('--'*20)\n",
    "\n",
    "#Precision Score \n",
    "print('Precision Score on train: ', precision_score(y_train, RF_train))\n",
    "precision_RF = precision_score(y_test, RF_pred).round(2) # Storing score in variable for display \n",
    "print(f'Precision Score on Test: {precision_RF}')\n",
    "print('--'*20)\n",
    "\n",
    "# Recall Score\n",
    "print('Recall Score on train: ', recall_score(y_train, RF_train))\n",
    "recall_RF = recall_score(y_test, RF_pred).round(2) # Storing score in variable for display \n",
    "print(f'Recall Score on Test: {recall_RF}')\n",
    "print('--'*20)\n",
    "\n",
    "# roc_auc_score\n",
    "print('AUC-ROC Score on Train: ', roc_auc_score(y_train, RF_train))\n",
    "roc_auc_RF = roc_auc_score(y_test, RF_pred).round(2)\n",
    "print(f'Recall Score on Test: {roc_auc_RF}')\n",
    "print('--'*20)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_RF = metrics.cohen_kappa_score(y_test, RF_pred).round(2)\n",
    "print(f'Kappa Score on Test: {kappa_RF}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train:  0.781875\n",
      "Accuracy Score on Test: 0.79\n",
      "----------------------------------------\n",
      "Precision Score on train:  0.375\n",
      "Precision Score on Test: 0.33\n",
      "----------------------------------------\n",
      "Recall Score on train:  0.08348457350272233\n",
      "Recall Score on Test: 0.09\n",
      "----------------------------------------\n",
      "AUC-ROC Score on Train:  0.5236234904696533\n",
      "AUC_ROC Score on Test: 0.52\n",
      "----------------------------------------\n",
      "Kappa Score on Test: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "NB = GaussianNB()\n",
    "# Fitting Model\n",
    "NB.fit(X_train, y_train)\n",
    "\n",
    "# Model Prediction for train \n",
    "NB_train = NB.predict(X_train) \n",
    "# prediction for test\n",
    "NB_pred = NB.predict(X_test)\n",
    "\n",
    "# Evaluation of Results\n",
    "print('Accuracy Score on Train: ', accuracy_score(y_train, NB_train))\n",
    "accuracy_NB = accuracy_score(y_test, NB_pred).round(2) # Storing score in variable for display \n",
    "print(f'Accuracy Score on Test: {accuracy_NB}')\n",
    "print('--'*20)\n",
    "\n",
    "#Precision Score \n",
    "print('Precision Score on train: ', precision_score(y_train, NB_train))\n",
    "precision_NB = precision_score(y_test, NB_pred).round(2) # Storing score in variable for display \n",
    "print(f'Precision Score on Test: {precision_NB}')\n",
    "print('--'*20)\n",
    "\n",
    "# Recall Score\n",
    "print('Recall Score on train: ', recall_score(y_train, NB_train))\n",
    "recall_NB = recall_score(y_test, NB_pred).round(2) # Storing score in variable for display \n",
    "print(f'Recall Score on Test: {recall_NB}')\n",
    "print('--'*20)\n",
    "\n",
    "# roc_auc_score\n",
    "print('AUC-ROC Score on Train: ', roc_auc_score(y_train, NB_train))\n",
    "roc_auc_NB = roc_auc_score(y_test, NB_pred).round(2) # Storing score in variable for display \n",
    "print(f'AUC_ROC Score on Test: {roc_auc_NB}')\n",
    "print('--'*20)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_NB = metrics.cohen_kappa_score(y_test, NB_pred).round(2) # Storing score in variable for display \n",
    "print(f'Kappa Score on Test: {kappa_DT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train:  0.778375\n",
      "Accuracy Score on Test: 0.79\n",
      "----------------------------------------\n",
      "Precision Score on Train: 0.2777777777777778\n",
      "Precision Score on Test: 0.24\n",
      "----------------------------------------\n",
      "Recall Score on Train: 0.045372050816696916\n",
      "Recall Score on Test: 0.05\n",
      "----------------------------------------\n",
      "AUC-ROC Score on Train:  0.5073244372564656\n",
      "AUC_ROC Score on Test: 0.51\n",
      "----------------------------------------\n",
      "Kappa Score on Test: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Defining Model\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "# Prediction on Train\n",
    "SVM_train = SVM.predict(X_train)\n",
    "# Rpediction on Test\n",
    "SVM_pred = SVM.predict(X_test)\n",
    "\n",
    "# Evaluation of Results\n",
    "print('Accuracy Score on Train: ', accuracy_score(y_train, SVM_train)) \n",
    "accuracy_svm = accuracy_score(y_test, SVM_pred).round(2) # Storing score in variable for display \n",
    "print(f'Accuracy Score on Test: {accuracy_svm}')\n",
    "print('--'*20)\n",
    "\n",
    "#Precision Score\n",
    "print('Precision Score on Train:', metrics.precision_score(y_train, SVM_train))\n",
    "precision_svm = metrics.precision_score(y_test, SVM_pred).round(2) # Storing score in variable for display \n",
    "print(f'Precision Score on Test: {precision_svm}')\n",
    "print('--'*20)\n",
    "\n",
    "# Recall Score\n",
    "print('Recall Score on Train:', metrics.recall_score(y_train, SVM_train))\n",
    "recall_svm = metrics.recall_score(y_test, SVM_pred).round(2) # Storing score in variable for display \n",
    "print(f'Recall Score on Test: {recall_svm}')\n",
    "print('--'*20)\n",
    "\n",
    "# roc_auc_score\n",
    "print('AUC-ROC Score on Train: ', roc_auc_score(y_train, SVM_train))\n",
    "roc_auc_svm = roc_auc_score(y_test, SVM_pred).round(2) # Storing score in variable for display \n",
    "print(f'AUC_ROC Score on Test: {roc_auc_svm}')\n",
    "print('--'*20)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_svm = metrics.cohen_kappa_score(y_test, SVM_pred).round(2) # Storing score in variable for display \n",
    "print(f'Kappa Score on Test: {kappa_svm}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Train:  0.957375\n",
      "Accuracy Score on Test: 0.87\n",
      "----------------------------------------\n",
      "Precision Score on Train: 0.9746743849493488\n",
      "Precision Score on Test: 0.69\n",
      "----------------------------------------\n",
      "Recall Score on Train: 0.8148820326678766\n",
      "Recall Score on Test: 0.55\n",
      "----------------------------------------\n",
      "AUC-ROC Score on Train:  0.9046838082041132\n",
      "AUC_ROC Score on Test: 0.75\n",
      "----------------------------------------\n",
      "Kappa Score on Test: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Defining and Fitting Model\n",
    "xgboost = xgb.XGBClassifier()\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# Prediction for Train\n",
    "xgb_train = xgboost.predict(X_train) \n",
    "# Predictioon for test\n",
    "xgb_pred = xgboost.predict(X_test)\n",
    "\n",
    "# Evaluation of Results\n",
    "print('Accuracy Score on Train: ', accuracy_score(y_train, xgb_train)) \n",
    "accuracy_xgb = accuracy_score(y_test, xgb_pred).round(2) # Storing score in variable for display \n",
    "print(f'Accuracy Score on Test: {accuracy_xgb}')\n",
    "print('--'*20)\n",
    "\n",
    "#Precision Score\n",
    "print('Precision Score on Train:', precision_score(y_train, xgb_train))\n",
    "precision_xgb = precision_score(y_test, xgb_pred).round(2) # Storing score in variable for display \n",
    "print(f'Precision Score on Test: {precision_xgb}')\n",
    "print('--'*20)\n",
    "\n",
    "# Recall Score\n",
    "print('Recall Score on Train:', recall_score(y_train, xgb_train))\n",
    "recall_xgb = recall_score(y_test, xgb_pred).round(2) # Storing score in variable for display \n",
    "print(f'Recall Score on Test: {recall_xgb}')\n",
    "print('--'*20)\n",
    "\n",
    "# roc_auc_score\n",
    "print('AUC-ROC Score on Train: ', roc_auc_score(y_train, xgb_train))\n",
    "roc_auc_xgb = roc_auc_score(y_test, xgb_pred).round(2) # Storing score in variable for display \n",
    "print(f'AUC_ROC Score on Test: {roc_auc_xgb}')\n",
    "print('--'*20)\n",
    "\n",
    "# Kappa Score\n",
    "kappa_xgb = metrics.cohen_kappa_score(y_test, xgb_pred).round(2) # Storing score in variable for display \n",
    "print(f'Kappa Score on Test: {kappa_xgb}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.8.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.10/site-packages (from prettytable) (0.2.6)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing prettytable library for display of results\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Create an instance of PrettyTable\n",
    "table = PrettyTable()\n",
    "\n",
    "# Define the column names\n",
    "table.field_names = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"AUC-ROC\", 'Kappa']\n",
    "\n",
    "# Add rows for each model's performance\n",
    "table.add_row([\"Logistic Regression\", accuracy_lr, precision_lr, recall_lr, roc_auc_lr, kappa_lr])\n",
    "table.add_row([\"Decision Tree\", accuracy_DT, precision_DT, recall_DT, roc_auc_DT, kappa_DT])\n",
    "table.add_row([\"Random Forest\", accuracy_RF, precision_RF, recall_RF, roc_auc_RF, kappa_RF])\n",
    "table.add_row([\"Naive Bayes\", accuracy_NB, precision_NB, recall_NB, roc_auc_NB, kappa_NB])\n",
    "table.add_row([\"Support Vector Machine\", accuracy_svm, precision_svm, recall_svm, roc_auc_svm, kappa_svm])\n",
    "table.add_row([\"XGBoost\", accuracy_xgb, precision_xgb, recall_xgb, roc_auc_xgb,kappa_xgb])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Evaluation Scores of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+-----------+--------+---------+-------+\n",
      "|         Model          | Accuracy | Precision | Recall | AUC-ROC | Kappa |\n",
      "+------------------------+----------+-----------+--------+---------+-------+\n",
      "|        XGBoost         |   0.87   |    0.69   |  0.55  |   0.75  |  0.54 |\n",
      "|     Random Forest      |   0.87   |    0.75   |  0.51  |   0.74  |  0.54 |\n",
      "|  Logistic Regression   |   0.8    |    0.38   |  0.07  |   0.52  |  0.06 |\n",
      "| Support Vector Machine |   0.79   |    0.24   |  0.05  |   0.51  |  0.02 |\n",
      "|      Naive Bayes       |   0.79   |    0.33   |  0.09  |   0.52  |  0.06 |\n",
      "|     Decision Tree      |   0.79   |    0.46   |  0.51  |   0.68  |  0.35 |\n",
      "+------------------------+----------+-----------+--------+---------+-------+\n"
     ]
    }
   ],
   "source": [
    "# Displaying PrettyTable that shows model and its accuracy on the test \n",
    "table.sortby = ('Accuracy')\n",
    "table.reversesort = True\n",
    "print(table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Random Forest** model performed the best with the best accuracy score, and has the highest chance of selecting the true positives. <br>\n",
    "- It has an accuracy score of `87%` meaning it can reliably predict churn.\n",
    "- It's precision and recall scores are `0.74` and `0.5` respectively, meaning it has a fairly high rate of correctly identifying True Positives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
